{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# BUSA 603 Lab 3: Market Mix Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Understand, run and interpret results of simple Marketing Mix Model with Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marketing Mix Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Marketing Mix Model (MMM) is a technique used to determine market attribution. Specifically, it is a statistical technique (usually regression) on marketing and sales data to estimate the impact of various marketing mix.\n",
    "\n",
    "Usually, Marketing Mix Models attempt to **measure the impact of immeasurable marketing channels**, like TV, radio, newspapers, social media, etc. \n",
    "\n",
    "MMM's subset, Attribution Modeling, is concerned about the impact of digital marketing touchpoints on conversion. Here the digital marketing touchpoints are instances in which a customer interacts with an element of the firm’s digital marketing efforts. The problem of marketing attribution is similar to generally analyzing the impact of the marketing mix on marketing outcomes. However, the focus of marketing attribution on digital marketing means that there is rich, granular data on the actions of each individual customer across a number of touchpoints. Marketing mix modeling is the starting place for marketing analytics professionals who want to apply statistical models to data.\n",
    "\n",
    "Generally, in MMM your output variable will be sales or conversions, but can also be things like website traffic. Your input variables typically consist of marketing spend by channel by period (day, week, month, quarter, etc…), but can also include other variables which we’ll get to later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a linear approach to modeling the relationship between a dependent (output) variable and one or more independent (input) variables. In simpler terms, it is the **line of best fit** that represents a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple linear regression\n",
    "\n",
    "Below is an example of a line that best fits the data points. The line is represented by the following equation:\n",
    "\n",
    "    \n",
    "$y = w_0 + w_1x$\n",
    "\n",
    "$w_0$ is the intercept and $w_1$ is the slop.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://github.com/franklin-univ-data-science/data/blob/master/images/10_01.png?raw=true\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This best-fitting line is also called the regression line. \n",
    "\n",
    "The distance between sample points ($y$) and regression line ($\\hat{y}$) are the offsets — the errors of our prediction. \n",
    "\n",
    "The difference between a sample point and the regression line is residual $y-\\hat{y}$.\n",
    "\n",
    "We also often use Sum of Squares Error (SSE) $SSE = \\sum_{i=1}^n(y^{(i)}-\\hat{y}^{(i)})^{2}$ for the error of regression model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple linear regression is useful when you want to find an equation that represents two variables, the independent variable (x) and the dependent variable (y). But what if you have many independent variables? For example, the price of a car is probably based on multiple factors, like its horsepower, the size of the car, and the value of the brand itself.\n",
    "\n",
    "This is when multiple regression comes in. Multiple regression is used to explain the relationship between a dependent variable and more than one independent variable.\n",
    "\n",
    "The image below shows a plot between Target (y) and Feature1 and Feature2 (x1 and x2). When there are two independent variables, a plane of best fit is found instead of a line of best fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://github.com/franklin-univ-data-science/data/blob/master/images/10_15.png?raw=true\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More generally, a linear system with m input variables is defined as:\n",
    "$y= w_0 + w_1x_1 + ... + w_mx_m $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Marketing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load  dataset into a data frame\n",
    "\n",
    "Let's load a fictional dataset that consists of marketing spend on TV, radio, and newspaper, as well as the corresponding dollar sales by period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Advertising.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "\n",
    "you can see that the variable, Unnamed: 0, is essentially an index starting at 1 — so we can remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, axis='columns' means we want to drop the column\n",
    "df = df.drop(['Unnamed: 0'],axis='columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is a simple dataset, there are a lot of steps that we don’t have to worry about, like handling outliers and missing values. But generally, you want to make sure that your dataset is clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the important characteristics of a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA) is an important and recommended first step prior to the training of a machine learning model. \n",
    "\n",
    "**Scatterplot matrix** allows us to visualize the pair-wise correlations between the different variables in this dataset in one place.\n",
    "\n",
    "Using the following scatterplot matrix, we can quickly eyeball how the data is distributed, the relationship between features and target, and whether the variables contain outliers. \n",
    "\n",
    "We will the seaborn library to draw the plots. Seaborn is a Python data visualization library that provides a high-level interface for drawing attractive and informative statistical graphics conveniently. Reference the exampels in the [Step-by-step Seaborn Tutorial](https://elitedatascience.com/python-seaborn-tutorial) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df, height=2.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be a strong relationship between TV and sales, less for radio, and even less for newspapers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the coefficient by OLS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary least squares (OLS) regression is a statistical method of analysis that estimates the relationship between one or more independent variables and a dependent variable; the method estimates the relationship by minimizing the sum of the squares in the difference between the observed and predicted values of the dependent variable, which is the residual we mentioned before. \n",
    "\n",
    "What makes Python so amazing is that it already has a library that we can use to create an OLS model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "model = sm.ols(formula=\"sales~TV+radio+newspaper\", data=df).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_pred'] = y_pred = model.predict()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the performance of linear regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual plots\n",
    "\n",
    "Since our model uses multiple explanatory variables, we can't visualize the linear regression line (or hyperplane to be precise) in a two-dimensional plot.\n",
    "\n",
    "But we can plot the residuals (**the differences between the actual and predicted values**) versus the predicted values to diagnose our regression model. **Residual plots** are a commonly used graphical tool for diagnosing regression models. They can help detect nonlinearity and outliers, and check whether the errors are randomly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(df['y_pred'],  df['sales'] - df['y_pred'],\n",
    "            c='steelblue', marker='o', edgecolor='white'\n",
    "            )\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.hlines(y=0, xmin=0, xmax=30, color='black', lw=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of a perfect prediction, the residuals would be precisely zero, which we will probably never encounter in real and practical applications. However, for a good regression model, we would expect that the errors are randomly distributed, and the residuals should be randomly scattered around the centerline. \n",
    "\n",
    "Suppose we see patterns in a residual plot. In that case, it means that our model is unable to capture some explanatory information, which has leaked into the residuals, as we can slightly see in our previous residual plot. Furthermore, we can also use residual plots to detect outliers, represented by the points with a significant deviation from the centerline.\n",
    "\n",
    "As the linear regression only catches the linear relationship between input and output, the inverted V shape in the residual plot is probably caused by the non-linear relationship between TV and sales. Also, one data point seems to be the outlier.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-squared\n",
    "\n",
    "Sometimes it is useful to report the coefficient of determination( $R^2$ ):\n",
    "\n",
    "\n",
    "$R^2 = \\frac{SST-SSE}{SST}$\n",
    "\n",
    "where $SST = \\sum_{i=1}^n(y^{(i)}-\\mu_y)^{2}$\n",
    "\n",
    "$SSE = \\sum_{i=1}^n(y^{(i)}-\\hat{y}^{(i)})^{2}$\n",
    "\n",
    "Here, SST is simply the total variance of the output variable, and SSE is the sum of squared fitting errors. Thus, $R^2$ can be understood as the **percentage of the response variance that is explained by a linear model**.\n",
    "\n",
    "In our fitting, The R-squared is 0.897, which means that almost 90% of all variations in our data can be explained by our model, which is pretty good. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret model results\n",
    "\n",
    "### p-values\n",
    "The p-value for each input variable tests the null hypothesis that the coefficient equals zero (no effect). A low p-value (<= 0.05) indicates that you can reject the null hypothesis. In other words, an input variable that has a low p-value is likely to be a meaningful improvement to your model because changes in the input variable's value are related to changes in the output variable. Conversely, a larger (insignificant) p-value suggests that changes in the input are not associated with changes in the output.\n",
    "\n",
    "In this case, the p-values of tv and radio are small (<0.05), while the p-value of the newspaper is large. Thus, only the tv and radio are meaningful input variables.\n",
    "\n",
    "### coefficients\n",
    "\n",
    "Regression coefficients represent the mean change in the output variable for one unit of change in the input variable while holding other inputs in the model constant. \n",
    "\n",
    "In this case, every 1 unit TV expense increases 0.0458 unit sales, and every 1 unit radio expense increases 0.1885 unit sales. Thus, the radio channel is more productive. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Considerations\n",
    "\n",
    "- In reality, the data probably won’t be as clean as this and the results probably won’t look as pretty. In practice, you’ll want to consider more variables that impact sales, including but not limited to\n",
    "seasonality. It’s almost always the case that company sales are seasonal. For example, a snowboard company’s sales would be much higher during the winter than in the summer. In practice, you’ll want to include a variable to account for seasonality.\n",
    "\n",
    "- Carryover Effects: The impact of marketing is not usually immediate. In many cases, consumers need time to think about their purchasing decisions after seeing advertisements. Carryover effects account for the time lag between when consumers are exposed to an ad and their response to the ad.\n",
    "\n",
    "- Base sales vs incremental sales: Not every sale is attributed to marketing. If a company spent absolutely nothing on marketing and still made sales, this would be called its base sales. Thus, to take it a step further, you could try to model advertising spend on incremental sales as opposed to total sales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reference: [How to Build a Simple Marketing Mix Model with Python](https://towardsdatascience.com/building-a-simple-marketing-mix-model-with-ols-571ac3d5b64f)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "The Red Bull data contains the sales amount and the expenses in dollars for the following channels:\n",
    "\n",
    "- Banner ad\n",
    "- Facebook\n",
    "- Instagram\n",
    "- E-zine\n",
    "- TV\n",
    "- Twitter\n",
    "- YouTube\n",
    "\n",
    "Action items:\n",
    "\n",
    "- Explore the data; discuss the relationship between the input variables and the output variable.\n",
    "- Apply the OLS model using all the input variables.\n",
    "- Evaluate the model performance; discuss the residual plot.\n",
    "- Find which channel is the best using linear regression, and explain why. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('redbull.csv')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
